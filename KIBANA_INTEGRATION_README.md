# ğŸ“Š YELP BIG DATA ANALYSIS - KIBANA INTEGRATION

Há»‡ thá»‘ng phÃ¢n tÃ­ch dá»¯ liá»‡u Yelp vá»›i **Batch Processing + Elasticsearch + Kibana Visualization**

---

## ğŸ¯ Tá»”NG QUAN

### Kiáº¿n trÃºc Hybrid

Káº¿t há»£p kiáº¿n trÃºc tá»« 2 nhÃ¡nh:
- **NhÃ¡nh hiá»‡n táº¡i**: Batch processing vá»›i 9 analyses (7 basic + 2 advanced)
- **NhÃ¡nh "hai"**: Elasticsearch + Kibana visualization infrastructure

### Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  YELP ANALYTICS PIPELINE                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚  â”‚  Data Sources   â”‚                                   â”‚
â”‚  â”‚  (JSON Files)   â”‚                                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚           â”‚                                            â”‚
â”‚           â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  PySpark Batch  â”‚â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Elasticsearch    â”‚     â”‚
â”‚  â”‚  Processing     â”‚        â”‚ (9 indices)      â”‚     â”‚
â”‚  â”‚  (9 Analyses)   â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚               â”‚
â”‚           â”‚                           â”‚               â”‚
â”‚           â”‚                           â–¼               â”‚
â”‚           â–¼                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚    Kibana        â”‚     â”‚
â”‚  â”‚  CSV Outputs    â”‚        â”‚  (Dashboards)    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš¡ QUICK START (3 bÆ°á»›c)

### BÆ°á»›c 1: Khá»Ÿi Ä‘á»™ng Elasticsearch + Kibana

```bash
# Khá»Ÿi Ä‘á»™ng services
docker-compose -f docker-compose-kibana.yml up -d

# Chá» services ready (~2-3 phÃºt)
docker-compose -f docker-compose-kibana.yml logs -f
```

**Kiá»ƒm tra**:
- Elasticsearch: http://localhost:9200
- Kibana: http://localhost:5601

### BÆ°á»›c 2: Cháº¡y Batch Analytics + LÆ°u vÃ o Elasticsearch

```bash
cd Spark_Batch

# Khá»Ÿi táº¡o indices vÃ  cháº¡y pipeline
python3 batch_main_elasticsearch.py \
  --data-path ./data/ \
  --init-indices
```

**Output**:
```
================================================================================
                YELP BIG DATA ANALYSIS WITH KIBANA
                     Batch Mode + Elasticsearch Integration
                          Run Time: 2025-12-16 11:00:00
================================================================================

Initializing Elasticsearch indices...
âœ“ Index 'yelp-analysis-1-top-selling' created successfully
âœ“ Index 'yelp-analysis-2-user-patterns' created successfully
...
âœ“ All indices initialized successfully!

Initializing pipeline...
  Data Path: ./data/
  Output Path: ./output_elasticsearch/
  Elasticsearch: localhost:9200

âœ“ Connected to Elasticsearch 8.11.3
âœ“ Elasticsearch connected successfully

================================================================================
DATA LOADING PHASE
================================================================================
Loading business data from ./data/
âœ“ Loaded 150,346 businesses
...

================================================================================
               RUNNING ALL ANALYSES WITH ELASTICSEARCH
================================================================================

[1/9] Running Analysis 1: Top Selling Products...
âœ“ Analysis 1 completed
âœ“ Saved to Elasticsearch: yelp-analysis-1-top-selling

[2/9] Running Analysis 2: User Purchase Patterns...
...

================================================================================
                     âœ“ ALL ANALYSES COMPLETED
================================================================================

âœ“ Analyses completed: 9
âœ“ CSV outputs: ./output_elasticsearch/
âœ“ Elasticsearch indices: 9
âœ“ Kibana dashboard: http://localhost:5601
```

### BÆ°á»›c 3: Táº¡o Kibana Dashboard

Xem hÆ°á»›ng dáº«n chi tiáº¿t: **[kibana_dashboards/KIBANA_SETUP_GUIDE.md](kibana_dashboards/KIBANA_SETUP_GUIDE.md)**

**TÃ³m táº¯t nhanh**:
1. Má»Ÿ Kibana: http://localhost:5601
2. Táº¡o 9 Data Views (index patterns)
3. Táº¡o visualizations cho má»—i analysis
4. Combine vÃ o 1 dashboard

---

## ğŸ“ Cáº¤U TRÃšC Dá»° ÃN

```
bigdata-2025-1/
â”‚
â”œâ”€â”€ docker-compose-kibana.yml          â† Docker services config
â”‚
â”œâ”€â”€ Spark_Batch/
â”‚   â”œâ”€â”€ batch_main_elasticsearch.py â­ â† Main entry point vá»›i ES integration
â”‚   â”œâ”€â”€ save_elasticsearch.py       â­ â† ES saver module
â”‚   â”‚
â”‚   â”œâ”€â”€ batch_main_v2.py              â† Original main (CSV only)
â”‚   â”œâ”€â”€ batch_pipeline.py             â† Pipeline orchestrator
â”‚   â”œâ”€â”€ batch_analytics.py            â† 7 analyses cÆ¡ báº£n
â”‚   â”œâ”€â”€ batch_analytics_advanced.py   â† 2 analyses nÃ¢ng cao
â”‚   â”œâ”€â”€ batch_udf.py                  â† UDF library
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ kibana_dashboards/
â”‚   â””â”€â”€ KIBANA_SETUP_GUIDE.md      â­ â† Chi tiáº¿t setup Kibana
â”‚
â”œâ”€â”€ KIBANA_INTEGRATION_README.md   â­ â† File nÃ y
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ business.json
    â”œâ”€â”€ review.json
    â””â”€â”€ user.json
```

â­ = Files má»›i cho Kibana integration

---

## ğŸ“Š 9 ANALYSES VÃ€ ELASTICSEARCH INDICES

| Analysis | Index Name | Visualization Type | Key Metrics |
|---|---|---|---|
| **1. Top Selling Products** | `yelp-analysis-1-top-selling` | Horizontal Bar Chart | review_count, avg_stars, name |
| **2. User Purchase Patterns** | `yelp-analysis-2-user-patterns` | Data Table | total_reviews, avg_stars, frequency |
| **3. Top Users by Reviews** | `yelp-analysis-3-top-users` | Metric / Table | review_count, useful_votes |
| **4. Category Trends** | `yelp-analysis-4-category-trends` | Line Chart | category, year, month, count |
| **5. High Rating Low Review** | `yelp-analysis-5-high-rating-low-review` | Scatter Plot | stars vs review_count |
| **6. Geographic Distribution** | `yelp-analysis-6-geographic` | Heat Map | city, state, business_count |
| **7. Seasonal Trends** | `yelp-analysis-7-seasonal` | Pie Chart | season, review_count |
| **8. Trending Businesses** â­ | `yelp-analysis-8-trending` | Line Chart | growth_rate, weekly_count |
| **9. Performance Matrix** â­ | `yelp-analysis-9-performance-matrix` | Heat Map | category Ã— city matrix |

â­ = Advanced analyses vá»›i Window Functions & Pivot/Unpivot

---

## ğŸš€ CÃC DEPLOYMENT MODES

### Mode 1: Local Development (Recommended Ä‘á»ƒ báº¯t Ä‘áº§u)

```bash
# 1. Start Elasticsearch + Kibana
docker-compose -f docker-compose-kibana.yml up -d

# 2. Run Spark locally (khÃ´ng qua Docker)
cd Spark_Batch
python3 batch_main_elasticsearch.py --data-path ./data/

# 3. Access Kibana
open http://localhost:5601
```

**Æ¯u Ä‘iá»ƒm**:
- Debug dá»… dÃ ng
- KhÃ´ng cáº§n build Docker image cho Spark
- Cháº¡y nhanh hÆ¡n

### Mode 2: Full Docker (Production-ready)

```bash
# TODO: Uncomment spark-batch service trong docker-compose-kibana.yml
# vÃ  build Docker image

docker-compose -f docker-compose-kibana.yml up -d --build
```

**Æ¯u Ä‘iá»ƒm**:
- Production-ready
- Isolated environment
- Easy deployment

### Mode 3: Hybrid with Streaming (Advanced)

Káº¿t há»£p vá»›i kiáº¿n trÃºc streaming tá»« nhÃ¡nh "hai":
```bash
# Merge features tá»« cáº£ 2 nhÃ¡nh
# - Batch analytics tá»« nhÃ¡nh hiá»‡n táº¡i
# - Kafka streaming tá»« nhÃ¡nh "hai"
# - Unified Elasticsearch + Kibana
```

---

## ğŸ”§ CONFIGURATION

### Elasticsearch Settings

File: `docker-compose-kibana.yml`

```yaml
elasticsearch:
  environment:
    - "ES_JAVA_OPTS=-Xms2g -Xmx2g"  # Heap size
    - discovery.type=single-node
    - xpack.security.enabled=false   # Disable security for dev
```

**Tuning**:
- RAM < 8GB: Set `-Xms1g -Xmx1g`
- RAM >= 16GB: Set `-Xms4g -Xmx4g`

### Spark Settings

File: `Spark_Batch/batch_configuration.py`

```python
.config("spark.driver.memory", "8g")
.config("spark.executor.memory", "4g")
```

**Tuning dá»±a trÃªn RAM**:
- 8GB RAM: driver=4g, executor=2g
- 16GB RAM: driver=8g, executor=4g
- 32GB+ RAM: driver=12g, executor=8g

### Environment Variables

```bash
# For Docker deployment
export ELASTICSEARCH_HOST=elasticsearch  # or localhost
export ELASTICSEARCH_PORT=9200
export DATA_PATH=/app/data
```

---

## ğŸ“– DOCUMENTATION MAP

### Äá»ƒ báº¯t Ä‘áº§u:
1. **README.md nÃ y** - Overview vÃ  quick start
2. **Spark_Batch/00_START_HERE.md** - Code structure
3. **kibana_dashboards/KIBANA_SETUP_GUIDE.md** - Kibana setup chi tiáº¿t

### Äá»ƒ hiá»ƒu code:
1. **Spark_Batch/PROJECT_STRUCTURE.md** - Cáº¥u trÃºc chi tiáº¿t 13 files
2. **Spark_Batch/ARCHITECTURE_DIAGRAM.md** - SÆ¡ Ä‘á»“ kiáº¿n trÃºc
3. **Spark_Batch/LOCAL_TEST_GUIDE.md** - Test features

### API Reference:
- **save_elasticsearch.py** - API documentation trong code
- **batch_main_elasticsearch.py** - Usage examples

---

## ğŸ› TROUBLESHOOTING

### Problem: "Cannot connect to Elasticsearch"

**Kiá»ƒm tra**:
```bash
# Check if ES is running
curl http://localhost:9200

# Check Docker containers
docker-compose -f docker-compose-kibana.yml ps

# Check logs
docker-compose -f docker-compose-kibana.yml logs elasticsearch
```

**Solution**:
```bash
# Restart services
docker-compose -f docker-compose-kibana.yml restart

# Or full restart
docker-compose -f docker-compose-kibana.yml down
docker-compose -f docker-compose-kibana.yml up -d
```

### Problem: "No data in Kibana"

**Kiá»ƒm tra**:
```bash
# Check if indices exist
curl http://localhost:9200/_cat/indices?v

# Check document count
curl http://localhost:9200/yelp-analysis-1-top-selling/_count
```

**Solution**:
```bash
# Re-run pipeline
cd Spark_Batch
python3 batch_main_elasticsearch.py --data-path ./data/ --init-indices
```

### Problem: OutOfMemoryError

**Solution 1: Giáº£m Elasticsearch heap**
```yaml
# docker-compose-kibana.yml
environment:
  - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
```

**Solution 2: Giáº£m Spark memory**
```python
# batch_configuration.py
.config("spark.driver.memory", "4g")
.config("spark.executor.memory", "2g")
```

**Solution 3: Limit data size**
```bash
# Process smaller data subset
python3 batch_main_elasticsearch.py --data-path ./data_small/
```

### Problem: Port conflicts (9200, 5601 already in use)

**Solution**:
```yaml
# Change ports in docker-compose-kibana.yml
elasticsearch:
  ports:
    - "9201:9200"  # Change from 9200

kibana:
  ports:
    - "5602:5601"  # Change from 5601
```

Then update code:
```bash
python3 batch_main_elasticsearch.py --es-port 9201
```

---

## ğŸ“ ADVANCED TOPICS

### 1. Real-time Updates

Enable auto-refresh trong Kibana:
```
Time Picker â†’ Auto-refresh â†’ 30s
```

Cháº¡y pipeline Ä‘á»‹nh ká»³:
```bash
# Cron job example (every hour)
0 * * * * cd /path/to/Spark_Batch && python3 batch_main_elasticsearch.py --data-path ./data/
```

### 2. Custom Visualizations

Táº¡o Vega visualizations cho advanced charts:
```json
{
  "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
  "data": {
    "url": {
      "index": "yelp-analysis-8-trending",
      "body": { "size": 100 }
    }
  },
  "mark": "line",
  "encoding": {
    "x": {"field": "week_start", "type": "temporal"},
    "y": {"field": "growth_rate", "type": "quantitative"}
  }
}
```

### 3. Machine Learning Integration

Use Kibana ML for anomaly detection:
```
Analytics â†’ Machine Learning â†’ Anomaly Detection
â†’ Create job â†’ Select index â†’ Configure metrics
```

### 4. Alerting

Set up alerts cho anomaly:
```
Stack Management â†’ Rules and Connectors â†’ Create rule
â†’ Elasticsearch query â†’ Define threshold â†’ Set actions
```

---

## ğŸ“ˆ PERFORMANCE TIPS

### 1. Batch Size Optimization

```python
# save_elasticsearch.py
# Adjust partition size for better performance
df = df.repartition(10)  # 10 partitions
df.foreachPartition(send_partition)
```

### 2. Index Optimization

```bash
# Force merge Ä‘á»ƒ optimize storage
curl -X POST "localhost:9200/yelp-analysis-*/_forcemerge?max_num_segments=1"
```

### 3. Query Performance

```bash
# Create alias cho multiple indices
curl -X POST "localhost:9200/_aliases" -H 'Content-Type: application/json' -d'
{
  "actions": [
    {"add": {"index": "yelp-analysis-*", "alias": "yelp-all"}}
  ]
}
'
```

### 4. Resource Monitoring

```bash
# Check cluster health
curl http://localhost:9200/_cluster/health?pretty

# Check node stats
curl http://localhost:9200/_nodes/stats?pretty
```

---

## ğŸ”— SO SÃNH Vá»šI NHÃNH "HAI"

| Feature | NhÃ¡nh "hai" | NhÃ¡nh hiá»‡n táº¡i (Integrated) |
|---|---|---|
| **Processing Mode** | Streaming (Kafka) | Batch |
| **Analyses** | 8 analyses | 9 analyses (7 basic + 2 advanced) |
| **Advanced Features** | Sentiment analysis | Window Functions, Pivot/Unpivot, UDF Library |
| **Elasticsearch** | âœ… | âœ… |
| **Kibana** | âœ… | âœ… |
| **Docker Setup** | Full stack (Kafka, HDFS, Spark) | Lightweight (ES + Kibana only) |
| **Deployment Complexity** | High (nhiá»u services) | Medium (ES + Kibana + Spark local) |
| **Use Case** | Real-time streaming | Batch analytics, periodic updates |

**Best of Both Worlds**:
- Use **nhÃ¡nh hiá»‡n táº¡i** cho: Batch analytics, complex analyses, development
- Use **nhÃ¡nh "hai"** cho: Real-time streaming, live updates
- **Merge** cáº£ 2 cho: Hybrid architecture vá»›i cáº£ batch vÃ  streaming

---

## ğŸ¯ NEXT STEPS

### Äá»ƒ tiáº¿p tá»¥c phÃ¡t triá»ƒn:

1. **Merge Streaming Features**:
   ```bash
   # Merge Kafka + streaming tá»« nhÃ¡nh "hai"
   git checkout claude/review-project-structure-pfDJE
   git merge hai --no-commit
   # Resolve conflicts
   ```

2. **Add More Analyses**:
   - Sentiment analysis (tá»« nhÃ¡nh "hai")
   - Time series forecasting
   - Recommendation system

3. **Production Deployment**:
   - Setup Kubernetes for scaling
   - Add monitoring (Prometheus + Grafana)
   - Implement CI/CD pipeline

4. **Advanced Visualizations**:
   - Custom Vega charts
   - Canvas for infographics
   - Maps cho geographic data

---

## ğŸ“ SUPPORT

### Documentation:
- **Kibana Setup**: `kibana_dashboards/KIBANA_SETUP_GUIDE.md`
- **Code Structure**: `Spark_Batch/PROJECT_STRUCTURE.md`
- **Architecture**: `Spark_Batch/ARCHITECTURE_DIAGRAM.md`

### Quick Commands:
```bash
# Start services
docker-compose -f docker-compose-kibana.yml up -d

# Run pipeline
cd Spark_Batch && python3 batch_main_elasticsearch.py --data-path ./data/

# Stop services
docker-compose -f docker-compose-kibana.yml down

# Clean everything
docker-compose -f docker-compose-kibana.yml down -v
```

---

**Happy Analyzing and Visualizing! ğŸ“ŠğŸ‰**

*Last Updated: 2025-12-16*
*Version: 2.0 - Kibana Integration*
*Branch: claude/review-project-structure-pfDJE*
