# ğŸ“ Cáº¤U TRÃšC Dá»° ÃN - YELP BIG DATA ANALYSIS (BATCH MODE)

## ğŸ“Š Tá»•ng quan

Dá»± Ã¡n phÃ¢n tÃ­ch dá»¯ liá»‡u Yelp sá»­ dá»¥ng PySpark vá»›i 2 phiÃªn báº£n:
- **V1 (Basic)**: 7 analyses cÆ¡ báº£n
- **V2 (Advanced)**: 9 analyses vá»›i cÃ¡c tÃ­nh nÄƒng Spark nÃ¢ng cao

---

## ğŸ—‚ï¸ Cáº¥u trÃºc thÆ° má»¥c

```
Spark_Batch/
â”‚
â”œâ”€â”€ ğŸ“‹ ENTRY POINTS (Äiá»ƒm khá»Ÿi cháº¡y)
â”‚   â”œâ”€â”€ batch_main.py              # Main V1 - Cháº¡y 7 analyses cÆ¡ báº£n
â”‚   â””â”€â”€ batch_main_v2.py           # Main V2 - Cháº¡y 9 analyses vá»›i tÃ­nh nÄƒng nÃ¢ng cao
â”‚
â”œâ”€â”€ ğŸ”§ CORE MODULES (Module cá»‘t lÃµi)
â”‚   â”œâ”€â”€ batch_configuration.py    # Cáº¥u hÃ¬nh Spark Session & schemas
â”‚   â”œâ”€â”€ batch_load_data.py        # Load dá»¯ liá»‡u tá»« JSON
â”‚   â””â”€â”€ batch_pipeline.py         # Pipeline orchestrator chÃ­nh
â”‚
â”œâ”€â”€ ğŸ“Š ANALYTICS MODULES (Module phÃ¢n tÃ­ch)
â”‚   â”œâ”€â”€ batch_analytics.py        # 7 analyses cÆ¡ báº£n (V1)
â”‚   â””â”€â”€ batch_analytics_advanced.py # 2 analyses nÃ¢ng cao (V2)
â”‚
â”œâ”€â”€ ğŸ¯ UDF LIBRARY (ThÆ° viá»‡n hÃ m tÃ¹y chá»‰nh)
â”‚   â””â”€â”€ batch_udf.py              # 7 UDFs (3 Regular + 4 Pandas UDF)
â”‚
â”œâ”€â”€ ğŸ§ª TESTING (Kiá»ƒm thá»­)
â”‚   â””â”€â”€ test_local_features.py    # Test suite cho 4 tÃ­nh nÄƒng nÃ¢ng cao
â”‚
â”œâ”€â”€ ğŸ› ï¸ UTILITIES (Tiá»‡n Ã­ch)
â”‚   â””â”€â”€ create_sample_data.py     # Táº¡o dá»¯ liá»‡u máº«u Ä‘á»ƒ test
â”‚
â””â”€â”€ ğŸ“š DOCUMENTATION (TÃ i liá»‡u)
    â”œâ”€â”€ README_BATCH.md           # HÆ°á»›ng dáº«n cÆ¡ báº£n
    â”œâ”€â”€ QUICKSTART.md             # Quick start guide
    â”œâ”€â”€ LOCAL_TEST_GUIDE.md       # HÆ°á»›ng dáº«n test local chi tiáº¿t
    â””â”€â”€ IMPLEMENTATION_PLAN_PA1.md # Káº¿ hoáº¡ch triá»ƒn khai Phase 1
```

---

## ğŸ” CHI TIáº¾T Tá»ªNG MODULE

### 1ï¸âƒ£ **ENTRY POINTS** - Äiá»ƒm khá»Ÿi cháº¡y

#### `batch_main.py` (185 dÃ²ng)
**Chá»©c nÄƒng**: Entry point cho phiÃªn báº£n V1 cÆ¡ báº£n

**CÃ¡c hÃ m chÃ­nh**:
- `main()` - HÃ m chÃ­nh khá»Ÿi cháº¡y pipeline
- `print_header()` - In header thÃ´ng tin
- `print_footer()` - In footer káº¿t quáº£

**CÃ¡ch sá»­ dá»¥ng**:
```bash
python batch_main.py --data-path ./data/ --output-path ./output/
```

**Flow**:
```
main() â†’ Parse args â†’ Create pipeline â†’ Load data â†’ Run 7 analyses â†’ Save results
```

---

#### `batch_main_v2.py` (324 dÃ²ng)
**Chá»©c nÄƒng**: Entry point cho phiÃªn báº£n V2 vá»›i tÃ­nh nÄƒng nÃ¢ng cao

**Class chÃ­nh**:
- `EnhancedYelpPipeline` - Káº¿ thá»«a tá»« `YelpAnalysisPipeline`, bá»• sung 2 analyses má»›i

**CÃ¡c hÃ m chÃ­nh**:
- `run_analysis_8()` - Trending Businesses (Window Functions)
- `run_analysis_9()` - Category Performance Matrix (Pivot/Unpivot)
- `run_all_analyses_v2()` - Cháº¡y táº¥t cáº£ 9 analyses

**CÃ¡ch sá»­ dá»¥ng**:
```bash
python batch_main_v2.py --data-path ./data/ --output-path ./output_v2/
```

**Flow**:
```
main() â†’ Create EnhancedPipeline â†’ Load data â†’ Run 9 analyses â†’ Save results
```

---

### 2ï¸âƒ£ **CORE MODULES** - Module cá»‘t lÃµi

#### `batch_configuration.py` (127 dÃ²ng)
**Chá»©c nÄƒng**: Quáº£n lÃ½ cáº¥u hÃ¬nh Spark vÃ  Ä‘á»‹nh nghÄ©a schemas

**Class chÃ­nh**:
- `SparkConfig` - Cáº¥u hÃ¬nh Spark Session
- `DataSchemas` - Äá»‹nh nghÄ©a schemas cho Business, Review, User

**CÃ¡c hÃ m quan trá»ng**:
```python
SparkConfig.create_spark_session()  # Táº¡o Spark Session vá»›i config tá»‘i Æ°u
DataSchemas.business_schema()       # Schema cho business.json
DataSchemas.review_schema()         # Schema cho review.json
DataSchemas.user_schema()           # Schema cho user.json
```

**Spark Config**:
- Driver memory: 8GB
- Executor memory: 4GB
- Shuffle partitions: 20
- Adaptive Query Execution: enabled
- Serializer: Kryo

---

#### `batch_load_data.py` (122 dÃ²ng)
**Chá»©c nÄƒng**: Load dá»¯ liá»‡u tá»« file JSON vÃ o DataFrame

**Class chÃ­nh**:
- `DataLoader` - Quáº£n lÃ½ viá»‡c load data

**CÃ¡c hÃ m chÃ­nh**:
```python
load_business_data()  # Load business.json â†’ business_df
load_review_data()    # Load review.json â†’ review_df
load_user_data()      # Load user.json â†’ user_df (optional)
```

**Input**: JSON files
**Output**: Spark DataFrames vá»›i schema Ä‘Ã£ Ä‘á»‹nh nghÄ©a

**VÃ­ dá»¥**:
```python
loader = DataLoader(spark, "./data/")
business_df = loader.load_business_data()  # Load 150,346 businesses
review_df = loader.load_review_data()      # Load 6,990,280 reviews
```

---

#### `batch_pipeline.py` (229 dÃ²ng)
**Chá»©c nÄƒng**: Orchestrator chÃ­nh Ä‘iá»u phá»‘i toÃ n bá»™ pipeline

**Class chÃ­nh**:
- `YelpAnalysisPipeline` - Pipeline orchestrator

**CÃ¡c hÃ m chÃ­nh**:
```python
load_data()           # Load táº¥t cáº£ datasets
run_analysis_1()      # Top Selling Products
run_analysis_2()      # User Purchase Patterns
run_analysis_3()      # Top Users by Reviews
run_analysis_4()      # Category Trends Over Time
run_analysis_5()      # High Rating Low Review Count
run_analysis_6()      # Geographic Distribution
run_analysis_7()      # Seasonal Trends
run_all_analyses()    # Cháº¡y táº¥t cáº£ 7 analyses
save_results()        # LÆ°u káº¿t quáº£ ra file
```

**Dependency**:
- Sá»­ dá»¥ng `batch_configuration.py` Ä‘á»ƒ khá»Ÿi táº¡o Spark
- Sá»­ dá»¥ng `batch_load_data.py` Ä‘á»ƒ load data
- Sá»­ dá»¥ng `batch_analytics.py` Ä‘á»ƒ cháº¡y analyses

**Flow**:
```
Pipeline.__init__() â†’ load_data() â†’ run_analysis_X() â†’ save_results()
```

---

### 3ï¸âƒ£ **ANALYTICS MODULES** - Module phÃ¢n tÃ­ch

#### `batch_analytics.py` (335 dÃ²ng)
**Chá»©c nÄƒng**: 7 analyses cÆ¡ báº£n vá»›i Broadcast Join optimization

**Class chÃ­nh**:
- `YelpAnalytics` - Container cho 7 hÃ m phÃ¢n tÃ­ch

**Danh sÃ¡ch 7 Analyses**:

| ID | TÃªn Analysis | HÃ m | TÃ­nh nÄƒng | Output |
|---|---|---|---|---|
| 1 | Top Selling Products | `top_selling_products_recent()` | Broadcast Join | Top businesses theo review gáº§n Ä‘Ã¢y |
| 2 | User Purchase Patterns | `user_purchase_patterns()` | Aggregation | PhÃ¢n tÃ­ch hÃ nh vi user |
| 3 | Top Users by Reviews | `top_users_by_reviews()` | Broadcast Join | Top users theo sá»‘ lÆ°á»£ng review |
| 4 | Category Trends | `category_trends_over_time()` | Broadcast Join | Xu hÆ°á»›ng theo categories |
| 5 | High Rating Low Review | `high_rating_low_review_businesses()` | Filter | Businesses Ã­t review nhÆ°ng rating cao |
| 6 | Geographic Distribution | `geographic_distribution()` | Broadcast Join | PhÃ¢n bá»‘ theo Ä‘á»‹a lÃ½ |
| 7 | Seasonal Trends | `seasonal_trends()` | Time-based | Xu hÆ°á»›ng theo mÃ¹a |

**TÃ­nh nÄƒng ná»•i báº­t**:
- âœ… **Broadcast Join**: Optimized cho join vá»›i báº£ng nhá» (analyses 1, 3, 4, 6)
- âœ… **Caching**: Cache DataFrame Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng
- âœ… **Salted Aggregation**: Xá»­ lÃ½ data skew

**VÃ­ dá»¥ sá»­ dá»¥ng**:
```python
analytics = YelpAnalytics()
result = analytics.top_selling_products_recent(
    review_df, business_df, days=15, top_n=10
)
result.show()
```

---

#### `batch_analytics_advanced.py` (473 dÃ²ng)
**Chá»©c nÄƒng**: 2 analyses nÃ¢ng cao vá»›i Window Functions vÃ  Pivot/Unpivot

**Class chÃ­nh**:
- `AdvancedYelpAnalytics` - Container cho analyses nÃ¢ng cao

**Danh sÃ¡ch 2 Analyses NÃ¢ng cao**:

| ID | TÃªn Analysis | HÃ m | TÃ­nh nÄƒng | Output |
|---|---|---|---|---|
| 8 | Trending Businesses | `trending_businesses()` | Window Functions | Businesses Ä‘ang trending vá»›i growth rate |
| 9 | Category Performance Matrix | `category_performance_matrix()` | Pivot/Unpivot | Ma tráº­n performance theo category & city |

**Analysis 8 - Trending Businesses**:
```python
trending_businesses(review_df, business_df, window_days=90, top_n=10)
```
**Window Functions sá»­ dá»¥ng**:
- `lag()` - So sÃ¡nh vá»›i tuáº§n trÆ°á»›c
- `lead()` - NhÃ¬n trÆ°á»›c tuáº§n sau
- `avg() over window` - Moving average 4 tuáº§n
- `dense_rank()` - Ranking businesses theo growth rate
- `rowsBetween(-3, 0)` - Sliding window

**Output**: Top businesses cÃ³ tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng cao nháº¥t

---

**Analysis 9 - Category Performance Matrix**:
```python
category_performance_matrix(business_df, review_df, top_categories=10, top_cities=5)
```
**Pivot/Unpivot Operations**:
- `pivot()` - Chuyá»ƒn long â†’ wide format (categories lÃ m rows, cities lÃ m columns)
- `stack()` - Chuyá»ƒn wide â†’ long format (unpivot)
- Cross-tabulation analysis

**Output**: Ma tráº­n hiá»‡u suáº¥t categories Ã— cities vá»›i avg rating & review count

---

### 4ï¸âƒ£ **UDF LIBRARY** - ThÆ° viá»‡n hÃ m tÃ¹y chá»‰nh

#### `batch_udf.py` (443 dÃ²ng)
**Chá»©c nÄƒng**: ThÆ° viá»‡n 7 User Defined Functions

**Danh sÃ¡ch UDFs**:

#### **Regular UDFs** (Xá»­ lÃ½ tá»«ng row - cháº­m hÆ¡n)

| UDF | Input | Output | Chá»©c nÄƒng |
|---|---|---|---|
| `categorize_rating()` | stars: int | string | PhÃ¢n loáº¡i rating: "Excellent" / "Good" / "Average" / "Poor" |
| `is_weekend()` | date: datetime | boolean | Kiá»ƒm tra cÃ³ pháº£i cuá»‘i tuáº§n khÃ´ng |
| `extract_city_state()` | address: string | string | TrÃ­ch xuáº¥t "City, State" tá»« Ä‘á»‹a chá»‰ |

**VÃ­ dá»¥**:
```python
from batch_udf import categorize_rating

df = df.withColumn("rating_category", categorize_rating(col("stars")))
# Output: 5 stars â†’ "Excellent", 1 star â†’ "Poor"
```

---

#### **Pandas UDFs** (Xá»­ lÃ½ vectorized - nhanh hÆ¡n 10-100x)

| UDF | Input | Output | Chá»©c nÄƒng |
|---|---|---|---|
| `sentiment_score()` | text: string | float | Äiá»ƒm sentiment tá»« 0.0-1.0 (0=negative, 1=positive) |
| `extract_keywords()` | text: string | string | TrÃ­ch xuáº¥t top 3 keywords quan trá»ng |
| `text_length_normalized()` | text: string | float | Äá»™ dÃ i text chuáº©n hÃ³a 0.0-1.0 |
| `extract_hashtags()` | text: string | string | TrÃ­ch xuáº¥t hashtags tá»« text |

**VÃ­ dá»¥**:
```python
from batch_udf import sentiment_score

df = df.withColumn("sentiment", sentiment_score(col("text")))
# Output: "Great food!" â†’ 0.9, "Terrible service" â†’ 0.1
```

**Performance Comparison**:
- Regular UDF: Process 10,000 rows ~ 5-10 seconds
- Pandas UDF: Process 10,000 rows ~ 0.1-0.5 seconds
- **Tá»‘c Ä‘á»™ cáº£i thiá»‡n: 10-100x**

---

### 5ï¸âƒ£ **TESTING** - Kiá»ƒm thá»­

#### `test_local_features.py` (355 dÃ²ng)
**Chá»©c nÄƒng**: Test suite toÃ n diá»‡n cho 4 tÃ­nh nÄƒng nÃ¢ng cao

**Class chÃ­nh**:
- `FeatureTester` - Test orchestrator

**CÃ¡c test functions**:

| Test | HÃ m | Kiá»ƒm tra |
|---|---|---|
| UDF Test | `test_udfs()` | Test 7 UDFs, so sÃ¡nh performance Regular vs Pandas |
| Window Functions | `test_window_functions()` | Test Analysis 8, verify lag/lead/rank |
| Pivot/Unpivot | `test_pivot_unpivot()` | Test Analysis 9, validate pivot/unpivot |
| Broadcast Join | `test_broadcast_join()` | Check physical plan cÃ³ BroadcastHashJoin |

**CÃ¡ch sá»­ dá»¥ng**:
```bash
# Test tá»«ng feature
python test_local_features.py --test udf
python test_local_features.py --test window
python test_local_features.py --test pivot
python test_local_features.py --test broadcast

# Test táº¥t cáº£
python test_local_features.py --test all
```

**Output**: In ra káº¿t quáº£ test, performance metrics, vÃ  status (âœ“/âœ—)

---

### 6ï¸âƒ£ **UTILITIES** - Tiá»‡n Ã­ch

#### `create_sample_data.py` (119 dÃ²ng)
**Chá»©c nÄƒng**: Táº¡o dá»¯ liá»‡u máº«u Ä‘á»ƒ test náº¿u khÃ´ng cÃ³ data tháº­t

**HÃ m chÃ­nh**:
```python
create_sample_business_data()  # Táº¡o 100 businesses máº«u
create_sample_review_data()    # Táº¡o 1000 reviews máº«u
```

**Output**:
- `data/sample_business.json` - 100 businesses
- `data/sample_review.json` - 1000 reviews

**CÃ¡ch sá»­ dá»¥ng**:
```bash
python create_sample_data.py
```

---

## ğŸ”„ DATA FLOW - Luá»“ng dá»¯ liá»‡u

### Pipeline V1 (Basic)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  batch_main.py  â”‚ Entry Point
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ batch_pipeline.py    â”‚ Orchestrator
â”‚ YelpAnalysisPipeline â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â–º batch_configuration.py (Spark Config)
           â”‚
           â”œâ”€â”€â”€â–º batch_load_data.py (Load Data)
           â”‚         â”‚
           â”‚         â”œâ”€ business.json â†’ business_df
           â”‚         â””â”€ review.json â†’ review_df
           â”‚
           â””â”€â”€â”€â–º batch_analytics.py (7 Analyses)
                     â”‚
                     â”œâ”€ Analysis 1: Top Selling
                     â”œâ”€ Analysis 2: User Patterns
                     â”œâ”€ Analysis 3: Top Users
                     â”œâ”€ Analysis 4: Category Trends
                     â”œâ”€ Analysis 5: High Rating Low Review
                     â”œâ”€ Analysis 6: Geographic
                     â””â”€ Analysis 7: Seasonal
                           â”‚
                           â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  output/*.csv  â”‚ Results
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pipeline V2 (Advanced)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ batch_main_v2.py â”‚ Entry Point
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ batch_main_v2.py        â”‚
â”‚ EnhancedYelpPipeline    â”‚ (káº¿ thá»«a YelpAnalysisPipeline)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â–º batch_pipeline.py (Base Pipeline)
           â”‚          â”‚
           â”‚          â””â”€â–º Cháº¡y 7 analyses cÆ¡ báº£n
           â”‚
           â”œâ”€â”€â”€â–º batch_udf.py (UDF Library)
           â”‚          â”‚
           â”‚          â””â”€â–º 7 UDFs (3 Regular + 4 Pandas)
           â”‚
           â””â”€â”€â”€â–º batch_analytics_advanced.py (2 Analyses NÃ¢ng cao)
                      â”‚
                      â”œâ”€ Analysis 8: Trending (Window Functions)
                      â””â”€ Analysis 9: Performance Matrix (Pivot/Unpivot)
                            â”‚
                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ output_v2/*.csv â”‚ Results
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ FUNCTION MAPPING - HÃ m nÃ o á»Ÿ Ä‘Ã¢u?

### Cáº§n táº¡o Spark Session?
âœ **`batch_configuration.py`**
```python
from batch_configuration import SparkConfig
spark = SparkConfig.create_spark_session()
```

### Cáº§n load dá»¯ liá»‡u?
âœ **`batch_load_data.py`**
```python
from batch_load_data import DataLoader
loader = DataLoader(spark, "./data/")
business_df = loader.load_business_data()
```

### Cáº§n cháº¡y analyses cÆ¡ báº£n?
âœ **`batch_analytics.py`**
```python
from batch_analytics import YelpAnalytics
analytics = YelpAnalytics()
result = analytics.top_selling_products_recent(review_df, business_df)
```

### Cáº§n cháº¡y analyses nÃ¢ng cao?
âœ **`batch_analytics_advanced.py`**
```python
from batch_analytics_advanced import AdvancedYelpAnalytics
advanced = AdvancedYelpAnalytics()
result = advanced.trending_businesses(review_df, business_df)
```

### Cáº§n sá»­ dá»¥ng UDF?
âœ **`batch_udf.py`**
```python
from batch_udf import sentiment_score, categorize_rating
df = df.withColumn("sentiment", sentiment_score(col("text")))
```

### Cáº§n cháº¡y toÃ n bá»™ pipeline?
âœ **`batch_main.py`** (V1) hoáº·c **`batch_main_v2.py`** (V2)
```bash
python batch_main_v2.py --data-path ./data/
```

---

## ğŸ”— DEPENDENCY GRAPH - Quan há»‡ giá»¯a cÃ¡c modules

```
batch_main_v2.py
    â”‚
    â”œâ”€â–º batch_pipeline.py
    â”‚       â”‚
    â”‚       â”œâ”€â–º batch_configuration.py
    â”‚       â”œâ”€â–º batch_load_data.py
    â”‚       â”‚       â””â”€â–º batch_configuration.py (schemas)
    â”‚       â””â”€â–º batch_analytics.py
    â”‚
    â”œâ”€â–º batch_analytics_advanced.py
    â”‚       â””â”€â–º batch_udf.py
    â”‚
    â””â”€â–º (khÃ´ng phá»¥ thuá»™c trá»±c tiáº¿p)
            test_local_features.py
            create_sample_data.py
```

**Dependencies theo module**:

| Module | Depends On |
|---|---|
| `batch_configuration.py` | pyspark (external) |
| `batch_load_data.py` | batch_configuration.py |
| `batch_analytics.py` | pyspark.sql.functions |
| `batch_analytics_advanced.py` | batch_udf.py |
| `batch_pipeline.py` | batch_configuration, batch_load_data, batch_analytics |
| `batch_main.py` | batch_pipeline |
| `batch_main_v2.py` | batch_pipeline, batch_analytics_advanced |
| `test_local_features.py` | ALL analytics modules |

---

## ğŸ“ QUICK REFERENCE - Tra cá»©u nhanh

### Muá»‘n cháº¡y toÃ n bá»™ pipeline?
```bash
# V1: 7 analyses cÆ¡ báº£n
python batch_main.py --data-path ./data/

# V2: 9 analyses (7 cÆ¡ báº£n + 2 nÃ¢ng cao)
python batch_main_v2.py --data-path ./data/
```

### Muá»‘n test cÃ¡c tÃ­nh nÄƒng nÃ¢ng cao?
```bash
# Test táº¥t cáº£
python test_local_features.py --test all

# Test tá»«ng feature
python test_local_features.py --test udf
python test_local_features.py --test window
python test_local_features.py --test pivot
python test_local_features.py --test broadcast
```

### Muá»‘n táº¡o dá»¯ liá»‡u máº«u?
```bash
python create_sample_data.py
```

### Muá»‘n sá»­ dá»¥ng tá»«ng module riÃªng láº»?
```python
# Example: Chá»‰ cháº¡y Analysis 8
from batch_configuration import SparkConfig
from batch_load_data import DataLoader
from batch_analytics_advanced import AdvancedYelpAnalytics

spark = SparkConfig.create_spark_session()
loader = DataLoader(spark, "./data/")
review_df = loader.load_review_data()
business_df = loader.load_business_data()

advanced = AdvancedYelpAnalytics()
result = advanced.trending_businesses(review_df, business_df, window_days=90, top_n=10)
result.show()
```

---

## ğŸ“ Há»ŒC Tá»ª CODE NÃ€Y

### Patterns sá»­ dá»¥ng trong dá»± Ã¡n:

1. **Separation of Concerns**: Má»—i module cÃ³ trÃ¡ch nhiá»‡m rÃµ rÃ ng
   - Configuration â†’ `batch_configuration.py`
   - Data Loading â†’ `batch_load_data.py`
   - Analytics Logic â†’ `batch_analytics.py`, `batch_analytics_advanced.py`
   - Orchestration â†’ `batch_pipeline.py`

2. **Class-based Architecture**: Sá»­ dá»¥ng static methods cho analytics
   ```python
   class YelpAnalytics:
       @staticmethod
       def analysis_name():
           # Logic
   ```

3. **Inheritance**: EnhancedPipeline káº¿ thá»«a YelpAnalysisPipeline
   ```python
   class EnhancedYelpPipeline(YelpAnalysisPipeline):
       # Extends functionality
   ```

4. **Performance Optimization**:
   - Broadcast Join cho small tables
   - Caching DataFrame Ä‘á»ƒ reuse
   - Pandas UDF cho vectorization
   - Salted Aggregation cho data skew

5. **Error Handling**: Try-except trong má»—i analysis function

6. **Modularity**: Má»—i analysis cÃ³ thá»ƒ cháº¡y Ä‘á»™c láº­p

---

## ğŸ“Š STATISTICS - Thá»‘ng kÃª dá»± Ã¡n

| Metric | Value |
|---|---|
| **Tá»•ng sá»‘ dÃ²ng code** | 2,712 dÃ²ng Python |
| **Sá»‘ modules** | 9 Python files |
| **Sá»‘ analyses** | 9 (7 basic + 2 advanced) |
| **Sá»‘ UDFs** | 7 (3 Regular + 4 Pandas) |
| **Spark features** | 15+ (Join, Window, Pivot, UDF, Broadcast, etc.) |
| **Test coverage** | 4 feature tests |
| **Documentation** | 5 markdown files |

---

## ğŸš€ NEXT STEPS - BÆ°á»›c tiáº¿p theo

### Äá»ƒ báº¯t Ä‘áº§u:
1. âœ… Äá»c file nÃ y Ä‘á»ƒ hiá»ƒu cáº¥u trÃºc
2. âœ… Äá»c `LOCAL_TEST_GUIDE.md` Ä‘á»ƒ biáº¿t cÃ¡ch test
3. âœ… Cháº¡y `python test_local_features.py --test all`
4. âœ… Cháº¡y `python batch_main_v2.py --data-path ./data/`

### Äá»ƒ má»Ÿ rá»™ng:
- ThÃªm analyses má»›i vÃ o `batch_analytics_advanced.py`
- ThÃªm UDFs má»›i vÃ o `batch_udf.py`
- ThÃªm test cases vÃ o `test_local_features.py`
- Tá»‘i Æ°u performance trong `batch_configuration.py`

---

## â“ CÃ‚U Há»I THÆ¯á»œNG Gáº¶P

**Q: Táº¡i sao cÃ³ 2 entry points (batch_main.py vÃ  batch_main_v2.py)?**
A: `batch_main.py` lÃ  phiÃªn báº£n V1 cÆ¡ báº£n vá»›i 7 analyses. `batch_main_v2.py` lÃ  V2 nÃ¢ng cao vá»›i 9 analyses + tÃ­nh nÄƒng Spark nÃ¢ng cao.

**Q: TÃ´i nÃªn sá»­ dá»¥ng file nÃ o Ä‘á»ƒ cháº¡y?**
A: Sá»­ dá»¥ng `batch_main_v2.py` Ä‘á»ƒ cÃ³ Ä‘áº§y Ä‘á»§ tÃ­nh nÄƒng nháº¥t (9 analyses).

**Q: LÃ m sao biáº¿t code cÃ³ hoáº¡t Ä‘á»™ng khÃ´ng?**
A: Cháº¡y `python test_local_features.py --test all` Ä‘á»ƒ kiá»ƒm tra.

**Q: Muá»‘n thÃªm analysis má»›i thÃ¬ sá»­a file nÃ o?**
A: ThÃªm hÃ m static method vÃ o `batch_analytics_advanced.py`, sau Ä‘Ã³ thÃªm `run_analysis_X()` vÃ o `EnhancedYelpPipeline` trong `batch_main_v2.py`.

**Q: UDF nÃ o nhanh hÆ¡n, Regular hay Pandas?**
A: Pandas UDF nhanh hÆ¡n 10-100x vÃ¬ xá»­ lÃ½ vectorized. Sá»­ dá»¥ng Pandas UDF khi cÃ³ thá»ƒ.

---

## ğŸ“ LIÃŠN Há»† & Há»– TRá»¢

- **Documentation**: Xem `LOCAL_TEST_GUIDE.md` cho hÆ°á»›ng dáº«n chi tiáº¿t
- **Quick Start**: Xem `QUICKSTART.md`
- **Implementation Plan**: Xem `IMPLEMENTATION_PLAN_PA1.md`

---

**Last Updated**: 2025-12-16
**Version**: 2.0 (Advanced Features)
**Author**: Claude Code Pipeline
