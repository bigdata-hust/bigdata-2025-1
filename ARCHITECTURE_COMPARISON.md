# ğŸ—ï¸ SO SÃNH KIáº¾N TRÃšC: NHÃNH HAI vs CÃC PHÆ¯Æ NG ÃN LOCAL

## ğŸ“Š Tá»”NG QUAN 3 KIáº¾N TRÃšC

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     KIáº¾N TRÃšC Gá»C - NHÃNH HAI                           â”‚
â”‚                        (Production Streaming)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Data Files (business.json, review.json, user.json)
         â”‚
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Kafka Producer â”‚  (Stream data vÃ o Kafka)
    â”‚  (Container)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      KAFKA CLUSTER                     â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚ Zookeeper â”‚ â†â†’ â”‚ Kafka Broker â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚   Topics: business, review, user      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   SPARK STREAMING           â”‚
    â”‚  - readStream from Kafka    â”‚
    â”‚  - 7 Analytics Functions    â”‚
    â”‚  - Watermarking             â”‚
    â”‚  - Checkpointing            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â†“              â†“               â†“              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    HDFS    â”‚  â”‚Elasticsearch â”‚  â”‚ MongoDB  â”‚  â”‚  Console â”‚
    â”‚  (Parquet) â”‚  â”‚  (7 indices) â”‚  â”‚(Optional)â”‚  â”‚  Output  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Kibana    â”‚
                    â”‚  Dashboard   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Services: 8+ containers
    RAM: 12-16GB
    Complexity: â­â­â­â­â­
    Setup: 30 phÃºt



â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PHÆ¯Æ NG ÃN 1 - SIMPLIFIED BATCH                        â”‚
â”‚                     (Development/Testing Mode)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Local Data Files (CSV/JSON/Parquet)
         â”‚
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   SPARK BATCH (Local)      â”‚
    â”‚  - spark.read() from files â”‚
    â”‚  - 7 Analytics Functions   â”‚
    â”‚  - No streaming overhead   â”‚
    â”‚  - Direct processing       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â†“              â†“                 â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Local    â”‚  â”‚Elasticsearch â”‚  â”‚   Console    â”‚
    â”‚   Files    â”‚  â”‚  (Optional)  â”‚  â”‚   Output     â”‚
    â”‚ (Parquet)  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  (show())    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Kibana    â”‚
                    â”‚  (Optional)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Services: 0-2 containers (chá»‰ ES+Kibana náº¿u cáº§n)
    RAM: 4-8GB
    Complexity: â­â­
    Setup: 5 phÃºt



â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                PHÆ¯Æ NG ÃN 2 - FULL DOCKER STACK                          â”‚
â”‚                    (Production Simulation)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    [GIá»NG KIáº¾N TRÃšC Gá»C - Cháº¡y trong Docker Compose]

    docker-compose up -d

    â†’ 8 containers khá»Ÿi Ä‘á»™ng tá»± Ä‘á»™ng
    â†’ Táº¥t cáº£ services káº¿t ná»‘i qua Docker network
    â†’ Data flow tá»± Ä‘á»™ng tá»« Producer â†’ Kafka â†’ Spark â†’ Outputs

    Services: 8 containers
    RAM: 12-16GB
    Complexity: â­â­â­â­
    Setup: 30 phÃºt
```

---

## ğŸ”„ LUá»’NG Xá»¬ LÃ 7 HÃ€M PHÃ‚N TÃCH

### NhÃ¡nh HAI (Streaming):
```python
# 1. Load data tá»« Kafka
business_df = spark.readStream.format("kafka")...
review_df = spark.readStream.format("kafka")...

# 2. Run analytics (streaming mode)
result = YelpAnalytics.top_selling_products_recent(review_df, business_df)
# â†’ result lÃ  streaming DataFrame

# 3. Output (streaming write)
result.writeStream
    .format("parquet")
    .outputMode("append")
    .option("checkpointLocation", "hdfs://...")
    .start()
    .awaitTermination()  # Chá» streaming cháº¡y liÃªn tá»¥c
```

### PhÆ°Æ¡ng Ã¡n 1 (Batch):
```python
# 1. Load data tá»« file local
business_df = spark.read.json("data/business.json")
review_df = spark.read.json("data/review.json")

# 2. Run analytics (batch mode)
result = YelpAnalytics.top_selling_products_recent(review_df, business_df)
# â†’ result lÃ  static DataFrame

# 3. Output (batch write)
result.show(10, truncate=False)  # Hiá»ƒn thá»‹ console
result.write.mode("overwrite").parquet("output/top_selling/")
```

---

## ğŸ“‹ CHI TIáº¾T 7 HÃ€M PHÃ‚N TÃCH

| # | TÃªn Analysis | Input | Logic chÃ­nh | Output Columns |
|---|--------------|-------|-------------|----------------|
| 1 | **Top Selling Products** | review_df + business_df | Filter N days gáº§n Ä‘Ã¢y â†’ Count reviews by business â†’ Join with business info | business_id, name, city, recent_review_count, avg_rating |
| 2 | **Diverse Stores** | business_df | Split categories â†’ Count unique categories per store | business_id, name, city, categories, category_count |
| 3 | **Best Rated** | business_df + review_df | Calc avg stars per business â†’ Filter min reviews â†’ Sort by rating | business_id, name, total_reviews, avg_review_stars, business_avg_stars |
| 4 | **Positive Reviews** | business_df + review_df | Count reviews >= threshold stars â†’ Calc positive ratio | business_id, name, positive_review_count, positive_ratio |
| 5 | **Peak Hours** | review_df | Extract year, month, hour from timestamp â†’ Count by time | year, month, hour, review_count |
| 6 | **Top Categories** | business_df + review_df | Explode categories â†’ Join reviews â†’ Count by category | category, total_reviews |
| 7 | **Store Stats** | business_df + review_df | Aggregate all metrics per store | business_id, name, actual_review_count, actual_avg_stars |

---

## ğŸ¯ MAPPING DEPENDENCIES

### Äá»ƒ cháº¡y cáº£ 7 hÃ m, báº¡n Cáº¦N:

#### Kiáº¿n trÃºc Gá»C (Docker Full):
```yaml
services:
  zookeeper:      # Port 2181
  kafka:          # Port 9092
  kafka-producer: # Push data vÃ o Kafka
  hdfs-namenode:  # Port 9000, 9870
  hdfs-datanode:  # Data storage
  elasticsearch:  # Port 9200
  kibana:         # Port 5601
  spark:          # Processing engine
```

#### PhÆ°Æ¡ng Ã¡n 1 (Batch Simplified):
```bash
# Báº¯t buá»™c:
- Python 3.8+
- Java 11+
- PySpark 4.0.1
- Data files (business.json, review.json)

# TÃ¹y chá»n (náº¿u muá»‘n visualize):
- Elasticsearch container
- Kibana container
```

#### PhÆ°Æ¡ng Ã¡n 2 (Docker):
```bash
# Same as Kiáº¿n trÃºc Gá»C
- Docker + Docker Compose
- 12GB+ RAM allocation
- Data files mount vÃ o container
```

---

## ğŸ’¾ YÃŠU Cáº¦U DATA FILES

### Format data cáº§n cÃ³:

#### business.json (hoáº·c CSV):
```json
{
  "business_id": "abc123",
  "name": "Example Restaurant",
  "city": "Phoenix",
  "state": "AZ",
  "categories": "Food, Restaurant, Italian",
  "stars": 4.5,
  "review_count": 120,
  "is_open": 1,
  "latitude": 33.4484,
  "longitude": -112.0740
}
```

#### review.json:
```json
{
  "review_id": "xyz789",
  "business_id": "abc123",
  "user_id": "user456",
  "stars": 5.0,
  "date": "2022-01-15 10:30:00",
  "text": "Great food!",
  "useful": 10,
  "funny": 2,
  "cool": 5
}
```

### KÃ­ch thÆ°á»›c data:
- **Small** (Test): 1K businesses, 10K reviews â†’ ~50MB
- **Medium** (Dev): 10K businesses, 100K reviews â†’ ~500MB
- **Large** (Production): 100K+ businesses, 1M+ reviews â†’ 5GB+

---

## âš™ï¸ CODE MODIFICATIONS CHO PHÆ¯Æ NG ÃN 1

### File: `batch_load_data.py`
```python
# BEFORE (Streaming):
def load_business_data(self):
    return (self.spark.readStream
        .format("kafka")
        .option("subscribe", "business")
        .load()
        .select(from_json(...))
    )

# AFTER (Batch):
def load_business_data(self):
    return self.spark.read.json(
        f"{self.data_path}/business.json",
        schema=self.schemas.business_schema()
    )
```

### File: `batch_pipeline.py`
```python
# BEFORE (Streaming):
def save_hdfs(self):
    df.writeStream
        .format("parquet")
        .option("checkpointLocation", "...")
        .start()
        .awaitTermination()

# AFTER (Batch):
def save_local(self):
    df.write
        .mode("overwrite")
        .parquet(f"{self.output_path}/{name}/")
```

### File: `batch_configuration.py`
```python
# REMOVE streaming configs:
- .config("spark.streaming.stopGracefullyOnShutdown", "true")
- .config("spark.sql.streaming.stateStore.providerClass", ...)
- spark.sparkContext.setCheckpointDir(...)

# KEEP batch configs:
.config("spark.driver.memory", "8g")
.config("spark.executor.memory", "4g")
```

### File: `analytics_yelp.py`
```python
# NO CHANGE NEEDED!
# CÃ¡c hÃ m analytics Ä‘Ã£ Ä‘Æ°á»£c viáº¿t Ä‘á»ƒ work vá»›i cáº£ streaming vÃ  batch
# Chá»‰ cáº§n remove cÃ¡c dÃ²ng .withWatermark() náº¿u cÃ³
```

---

## ğŸš¦ DECISION TREE: CHá»ŒN PHÆ¯Æ NG ÃN NÃ€O?

```
Báº¯t Ä‘áº§u
   â”‚
   â”œâ”€â†’ Má»¥c Ä‘Ã­ch gÃ¬?
   â”‚      â”‚
   â”‚      â”œâ”€â†’ Chá»‰ xem káº¿t quáº£ 7 phÃ¢n tÃ­ch?
   â”‚      â”‚      â””â”€â†’ PHÆ¯Æ NG ÃN 1 âœ…
   â”‚      â”‚
   â”‚      â”œâ”€â†’ Test full production stack?
   â”‚      â”‚      â””â”€â†’ PHÆ¯Æ NG ÃN 2 âœ…
   â”‚      â”‚
   â”‚      â””â”€â†’ Cáº£ hai?
   â”‚             â””â”€â†’ PA1 trÆ°á»›c, PA2 sau âœ…
   â”‚
   â”œâ”€â†’ RAM cÃ³ bao nhiÃªu?
   â”‚      â”‚
   â”‚      â”œâ”€â†’ < 8GB
   â”‚      â”‚      â””â”€â†’ PHÆ¯Æ NG ÃN 1 (chá»‰ lá»±a chá»n)
   â”‚      â”‚
   â”‚      â”œâ”€â†’ 8-12GB
   â”‚      â”‚      â””â”€â†’ PHÆ¯Æ NG ÃN 1 âœ… (PA2 cÃ³ thá»ƒ nhÆ°ng cháº­m)
   â”‚      â”‚
   â”‚      â””â”€â†’ > 12GB
   â”‚             â””â”€â†’ Cáº£ PA1 vÃ  PA2 Ä‘á»u OK âœ…
   â”‚
   â”œâ”€â†’ CÃ³ data files chÆ°a?
   â”‚      â”‚
   â”‚      â”œâ”€â†’ ChÆ°a cÃ³
   â”‚      â”‚      â””â”€â†’ PHÆ¯Æ NG ÃN 1 (táº¡o sample nhanh)
   â”‚      â”‚
   â”‚      â””â”€â†’ CÃ³ rá»“i (JSON format)
   â”‚             â””â”€â†’ Cáº£ PA1 vÃ  PA2 Ä‘á»u OK âœ…
   â”‚
   â”œâ”€â†’ Cáº§n real-time khÃ´ng?
   â”‚      â”‚
   â”‚      â”œâ”€â†’ KhÃ´ng, chá»‰ cáº§n káº¿t quáº£
   â”‚      â”‚      â””â”€â†’ PHÆ¯Æ NG ÃN 1 âœ…
   â”‚      â”‚
   â”‚      â””â”€â†’ CÃ³, cáº§n test streaming
   â”‚             â””â”€â†’ PHÆ¯Æ NG ÃN 2 âœ…
   â”‚
   â””â”€â†’ Kinh nghiá»‡m Docker?
          â”‚
          â”œâ”€â†’ Ãt hoáº·c khÃ´ng cÃ³
          â”‚      â””â”€â†’ PHÆ¯Æ NG ÃN 1 âœ…
          â”‚
          â””â”€â†’ CÃ³ kinh nghiá»‡m
                 â””â”€â†’ PHÆ¯Æ NG ÃN 2 OK âœ…
```

---

## ğŸ“ˆ PERFORMANCE COMPARISON

| Metric | NhÃ¡nh HAI (Docker) | PA1 (Batch) | PA2 (Docker) |
|--------|-------------------|-------------|--------------|
| **Setup Time** | 30 phÃºt | 5 phÃºt | 30 phÃºt |
| **First Run** | 15-20 phÃºt | 5-10 phÃºt | 15-20 phÃºt |
| **Memory Usage** | 12-16GB | 4-8GB | 12-16GB |
| **CPU Usage** | High | Medium | High |
| **Disk I/O** | High | Medium | High |
| **Network** | High (Kafka) | None | High (Kafka) |
| **Startup** | Slow (nhiá»u services) | Fast | Slow |
| **Debug** | KhÃ³ (multi-container) | Dá»… (single process) | KhÃ³ |
| **Scalability** | Excellent | Good | Excellent |

---

## âœ… FINAL RECOMMENDATION

### ğŸ¥‡ Náº¿u lÃ  láº§n Ä‘áº§u & muá»‘n XEM Káº¾T QUáº¢ NHANH:
â†’ **PHÆ¯Æ NG ÃN 1 (Batch)**
- Cháº¡y ngay sau 5 phÃºt setup
- Tháº¥y káº¿t quáº£ 7 phÃ¢n tÃ­ch trÃªn console
- KhÃ´ng cáº§n Docker
- Dá»… debug náº¿u cÃ³ lá»—i

### ğŸ¥ˆ Náº¿u muá»‘n Há»ŒC & HIá»‚U FULL STACK:
â†’ **PHÆ¯Æ NG ÃN 2 (Docker)**
- Giá»‘ng production
- Hiá»ƒu Ä‘Æ°á»£c cÃ¡ch cÃ¡c services káº¿t ná»‘i
- Tháº¥y Ä‘Æ°á»£c data flow tá»« Kafka â†’ Spark â†’ ES
- Táº¡o dashboard Ä‘áº¹p trÃªn Kibana

### ğŸ¥‰ Náº¿u cÃ³ THá»œI GIAN & TÃ€I NGUYÃŠN:
â†’ **Cáº¢ HAI**
1. Cháº¡y PA1 trÆ°á»›c Ä‘á»ƒ verify logic (30 phÃºt)
2. Cháº¡y PA2 sau Ä‘á»ƒ test full stack (1-2 giá»)

---

## ğŸ“ NEXT STEPS

**Sau khi Ä‘á»c file nÃ y, hÃ£y cho tÃ´i biáº¿t:**

1. Báº¡n chá»n phÆ°Æ¡ng Ã¡n nÃ o? (1, 2, hay cáº£ hai)
2. Báº¡n Ä‘Ã£ cÃ³ data files chÆ°a?
3. RAM mÃ¡y báº¡n bao nhiÃªu?
4. CÃ³ cÃ i Docker chÆ°a?

**TÃ´i sáº½ giÃºp báº¡n:**
- Táº¡o code cho phÆ°Æ¡ng Ã¡n Ä‘Ã£ chá»n
- Setup environment
- Cháº¡y vÃ  verify káº¿t quáº£
- Troubleshoot náº¿u cÃ³ lá»—i

**Let's get started! ğŸš€**
