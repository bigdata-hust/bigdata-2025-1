{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "220149ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SparkSession ,Window\n",
    "import time\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ce35e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/15 21:13:09 WARN Utils: Your hostname, Admin-PC, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/12/15 21:13:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/15 21:13:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.config('spark.driver.memory' , '8g').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eaf08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "business = spark.read.json(\"/home/mhai/Project DE/bigdata-2025-1/data/business.json\")\n",
    "review = spark.read.json(\"/home/mhai/Project DE/bigdata-2025-1/data/review.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aed9daae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "user = spark.read.json(\"/home/mhai/Project DE/bigdata-2025-1/data/user.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05d6a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "business = business.withColumn('business_ts' , current_timestamp()) \\\n",
    "                    .withWatermark('business_ts' , '10 minutes' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c07d462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = review.withColumn('review_ts' , current_timestamp()) \\\n",
    "                    .withWatermark('review_ts' , '10 minutes' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57cf21f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = user.withColumn('user_ts' , current_timestamp()) \\\n",
    "            .withWatermark('user_ts' , '10 minutes' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08cfc668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ANALYSIS FUNCTIONS - OPTIMIZED FOR BIG DATA\n",
    "# ============================================================================\n",
    "import pyspark\n",
    "\"\"\"\n",
    "Yelp Big Data Analysis System\n",
    "Optimized PySpark Pipeline for Large-Scale Data Processing\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, IntegerType, \n",
    "    DoubleType, TimestampType, BooleanType\n",
    ")\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from configuration import SparkConfig\n",
    "\n",
    "\n",
    "class YelpAnalytics:\n",
    "    \"\"\"Core analytics functions optimized for big data\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def top_selling_products_recent(review_df, business_df, days, top_n):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Analysis 1: Top {top_n} Selling Products (Last {days} days)\")\n",
    "        print(f\"{'='*60}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Add salt to handle skew\n",
    "        review_with_salt = review_df.withColumn(\"salt\", (rand() * 10).cast(\"int\"))\n",
    "        \n",
    "        # # Filter by date range\n",
    "        cutoff_date = date_sub(to_timestamp(lit(\"2022-01-19 00:00:00\"), \"yyyy-MM-dd HH:mm:ss\"), days)\n",
    "        review_with_salt = review_with_salt.withColumn('date' , to_timestamp(col('date') , 'yyyy-MM-dd HH:mm:ss'))\n",
    "        recent_reviews = review_with_salt.filter(col(\"date\") >= cutoff_date)\n",
    "        \n",
    "        # Stage 1: Salted aggregation\n",
    "        salted_agg = recent_reviews.groupBy(\"business_id\", \"salt\" , 'review_ts').agg(\n",
    "            count(\"review_id\").alias(\"partial_count\"),\n",
    "            sum(\"stars\").alias(\"partial_sum_stars\"),\n",
    "            count(\"stars\").alias(\"partial_count_stars\")\n",
    "        )\n",
    "        \n",
    "        # Stage 2: Final aggregation\n",
    "        business_stats = salted_agg.groupBy(\"business_id\" , 'review_ts').agg(\n",
    "            sum(\"partial_count\").alias(\"recent_review_count\"),\n",
    "            (sum(\"partial_sum_stars\") / sum(\"partial_count_stars\")).alias(\"avg_rating\")\n",
    "        )\n",
    "        \n",
    "        # Get top candidates before join\n",
    "        top_candidates = business_stats \\\n",
    "                        .limit(top_n * 10)  \n",
    "        #.orderBy(desc(\"recent_review_count\")) \\\n",
    "            \n",
    "        business_df = business_df.select(\"business_id\", \"name\", \"city\", \"state\", \"categories\" , 'business_ts') \n",
    "        # Broadcast join with business info\n",
    "        result = top_candidates.join(business_df , \"business_id\" , 'inner')\n",
    "        \n",
    "\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def top_stores_by_product_count(business_df, top_n=10):\n",
    "        \"\"\"\n",
    "        2. Cửa hàng bán nhiều sản phẩm nhất (dựa trên categories)\n",
    "        \n",
    "        Optimizations:\n",
    "        - Early null filtering\n",
    "        - Minimal column selection\n",
    "        - Efficient string processing\n",
    "        \n",
    "        Args:\n",
    "            business_df: DataFrame chứa dữ liệu business\n",
    "            top_n: số lượng top cửa hàng\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame với top cửa hàng đa dạng nhất\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Analysis 2: Top {top_n} Stores by Product Diversity\")\n",
    "        print(f\"{'='*60}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Filter and select only needed columns\n",
    "        business_filtered = business_df \\\n",
    "            .filter(col(\"categories\").isNotNull()) \\\n",
    "            .filter(length(col(\"categories\")) > 0) \\\n",
    "            .select(\n",
    "                \"business_id\", \"name\", \"city\", \"state\", \n",
    "                \"categories\", \"review_count\", \"stars\" , 'business_ts'\n",
    "            )\n",
    "        \n",
    "        # Count categories\n",
    "        result = business_filtered.withColumn(\n",
    "            \"category_count\",\n",
    "            size(split(trim(col(\"categories\")), \"\\\\s*,\\\\s*\"))\n",
    "        ).select(\n",
    "            \"business_id\",\n",
    "            \"name\",\n",
    "            \"city\",\n",
    "            \"state\",\n",
    "            \"categories\",\n",
    "            \"category_count\",\n",
    "            \"review_count\",\n",
    "            \"stars\",\n",
    "            'business_ts'\n",
    "        )\n",
    "        \n",
    "      \n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def top_rated_products(business_df, review_df, min_reviews=50, top_n=10):\n",
    "        \"\"\"\n",
    "        3. Sản phẩm (doanh nghiệp) đánh giá tích cực nhất\n",
    "        \n",
    "        Optimizations:\n",
    "        - Partitioning by business_id\n",
    "        - Strategic caching\n",
    "        - Early filtering by min_reviews\n",
    "        - Broadcast join\n",
    "        \n",
    "        Args:\n",
    "            business_df: DataFrame chứa dữ liệu business\n",
    "            review_df: DataFrame chứa dữ liệu review\n",
    "            min_reviews: số lượng review tối thiểu\n",
    "            top_n: số lượng top sản phẩm\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame với top sản phẩm có rating cao nhất\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Analysis 3: Top {top_n} Rated Products (Min {min_reviews} reviews)\")\n",
    "        print(f\"{'='*60}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Repartition and cache\n",
    "        review_partitioned = review_df \\\n",
    "            .select(\"business_id\", \"review_id\", \"stars\", \"useful\" , 'review_ts') \n",
    "           \n",
    "        \n",
    "        # Aggregate review stats\n",
    "        business_stats = review_partitioned \\\n",
    "            .filter(col(\"stars\").isNotNull()) \\\n",
    "            .groupBy(\"business_id\" , 'review_ts') \\\n",
    "            .agg(\n",
    "                count(\"review_id\").alias(\"total_reviews\"),\n",
    "                avg(\"stars\").alias(\"avg_review_stars\"),\n",
    "                sum(\"useful\").alias(\"total_useful\")\n",
    "            )\n",
    "        \n",
    "        # Filter by minimum reviews\n",
    "        qualified = business_stats.filter(col(\"total_reviews\") >= min_reviews)\n",
    "        \n",
    "        # Get top candidates\n",
    "        top_candidates = qualified \\\n",
    "            .limit(top_n * 5)\n",
    "        \n",
    "        # Broadcast join\n",
    "        result = top_candidates.join(\n",
    "            business_df.select(\n",
    "                \"business_id\", \"name\", \"city\", \"state\", \"categories\", \"stars\" , 'business_ts'\n",
    "            ),\n",
    "            \"business_id\" , 'inner'\n",
    "        ).select(\n",
    "            \"business_id\",\n",
    "            \"name\",\n",
    "            \"city\",\n",
    "            \"state\",\n",
    "            \"categories\",\n",
    "            \"total_reviews\",\n",
    "            \"avg_review_stars\",\n",
    "            \"total_useful\",\n",
    "            col(\"stars\").alias(\"business_avg_stars\") ,\n",
    "            # 'business_ts' ,\n",
    "            'review_ts'\n",
    "        )\n",
    "        \n",
    "      \n",
    "        \n",
    "        # Cleanup\n",
    "        review_partitioned.unpersist()\n",
    "        \n",
    "       \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def top_stores_by_positive_reviews(business_df, review_df, \n",
    "                                       positive_threshold=4, top_n=10):\n",
    "        \"\"\"\n",
    "        4. Cửa hàng nhận nhiều đánh giá tích cực nhất\n",
    "        \n",
    "        Optimizations:\n",
    "        - Single-pass aggregation with conditional logic\n",
    "        - Repartitioning and caching\n",
    "        - Early filtering\n",
    "        - Broadcast join\n",
    "        \n",
    "        Args:\n",
    "            business_df: DataFrame chứa dữ liệu business\n",
    "            review_df: DataFrame chứa dữ liệu review\n",
    "            positive_threshold: ngưỡng sao tích cực (default: 4)\n",
    "            top_n: số lượng top cửa hàng\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame với top cửa hàng có nhiều review tích cực nhất\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Analysis 4: Top {top_n} Stores by Positive Reviews (>= {positive_threshold} stars)\")\n",
    "        print(f\"{'='*60}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Repartition and cache\n",
    "        review_partitioned = review_df \\\n",
    "            .select(\"business_id\", \"review_id\", \"stars\", \"useful\" , 'review_ts') \n",
    "            \n",
    "\n",
    "        \n",
    "        # Single-pass aggregation with conditional logic\n",
    "        review_stats = review_partitioned.groupBy(\"business_id\" , 'review_ts').agg(\n",
    "            # Count positive reviews\n",
    "            sum(when(col(\"stars\") >= positive_threshold, 1).otherwise(0))\n",
    "                .alias(\"positive_review_count\"),\n",
    "            \n",
    "            # Total review count\n",
    "            count(\"review_id\").alias(\"total_review_count\"),\n",
    "            \n",
    "            # Average stars of positive reviews\n",
    "            avg(when(col(\"stars\") >= positive_threshold, col(\"stars\")))\n",
    "                .alias(\"avg_positive_rating\"),\n",
    "            \n",
    "            # Total useful votes from positive reviews\n",
    "            sum(when(col(\"stars\") >= positive_threshold, col(\"useful\")).otherwise(0))\n",
    "                .alias(\"total_useful_votes\")\n",
    "        )\n",
    "        \n",
    "        # Calculate positive ratio and filter\n",
    "        review_stats_filtered = review_stats \\\n",
    "            .withColumn(\n",
    "                \"positive_ratio\", \n",
    "                col(\"positive_review_count\") / col(\"total_review_count\")\n",
    "            ) \\\n",
    "            .filter(col(\"positive_review_count\") > 0)\n",
    "        \n",
    "        # Get top candidates\n",
    "        top_candidates = review_stats_filtered \\\n",
    "            .limit(top_n * 3)\n",
    "        \n",
    "        # Broadcast join\n",
    "        result = top_candidates.join(\n",
    "            business_df.select(\n",
    "                \"business_id\", \"name\", \"city\", \"state\", \"categories\" , 'business_ts'\n",
    "            ),\n",
    "            \"business_id\" , 'inner'\n",
    "        ).select(\n",
    "            \"business_id\",\n",
    "            \"name\",\n",
    "            \"city\",\n",
    "            \"state\",\n",
    "            \"categories\",\n",
    "            \"positive_review_count\",\n",
    "            \"total_review_count\",\n",
    "            \"positive_ratio\",\n",
    "            \"avg_positive_rating\",\n",
    "            \"total_useful_votes\" ,\n",
    "            # 'business_ts' , \n",
    "            'review_ts'\n",
    "        )\n",
    "        \n",
    "\n",
    "        \n",
    "        # Cleanup\n",
    "        review_partitioned.unpersist()\n",
    "        \n",
    "    \n",
    "        return result\n",
    "    \n",
    "\n",
    "    # ================================================================\n",
    "    # 5.Phân tích thời gian cao điểm (review nhiều nhất)\n",
    "    # ================================================================\n",
    "    @staticmethod\n",
    "    def get_peak_hours(review_df):\n",
    "        \"\"\"\n",
    "        Phân tích số lượng review theo năm / tháng / giờ.\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Analysis 2: Peak Review Hours (Activity Over Time)\")\n",
    "        print(f\"{'='*60}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Cột date có dạng \"yyyy-MM-dd HH:mm:ss\"\n",
    "        df = review_df.withColumn(\"date_parsed\", to_timestamp(col(\"date\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "        result = (\n",
    "            df.groupBy(\n",
    "                year(\"date_parsed\").alias(\"year\"),\n",
    "                month(\"date_parsed\").alias(\"month\") ,\n",
    "                'review_ts'\n",
    "            )\n",
    "            .agg(count(\"review_id\").alias(\"review_count\"))\n",
    "        )\n",
    "\n",
    "      \n",
    "        return result\n",
    "\n",
    "    # ================================================================\n",
    "    # 6. Top danh mục (category) có nhiều review nhất\n",
    "    # ================================================================\n",
    "    @staticmethod\n",
    "    def get_top_categories(business_df, review_df, top_n=20):\n",
    "        \"\"\"\n",
    "        Phân tích top danh mục (category) bán chạy nhất - dựa trên số lượng review.\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Analysis 3: Top {top_n} Categories by Review Count\")\n",
    "        print(f\"{'='*60}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Tách categories thành từng dòng riêng\n",
    "        df_business = business_df.withColumn(\"category\", explode(split(col(\"categories\"), \",\\\\s*\")))\n",
    "\n",
    "        # Join review với business\n",
    "        joined = review_df.join(df_business.select(\"business_id\", \"category\" , 'business_ts'), \"business_id\" , 'inner')\n",
    "\n",
    "        # Đếm số lượng review cho từng category\n",
    "        result = (\n",
    "            joined.groupBy(\"category\" , 'review_ts' )\n",
    "            .agg(count(\"review_id\").alias(\"total_reviews\"))\n",
    "        )\n",
    "\n",
    "        \n",
    "        return result\n",
    "\n",
    "    # ================================================================\n",
    "    # 7 Thống kê thông tin tất cả cửa hàng\n",
    "    # ================================================================\n",
    "    @staticmethod\n",
    "    def get_store_stats(business_df, review_df):\n",
    "        \"\"\"\n",
    "        Trả về thống kê tổng hợp của tất cả cửa hàng:\n",
    "        - Tên, danh mục, điểm sao trung bình, tổng số review thực tế,...\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Analysis 4: Store Statistics Summary\")\n",
    "        print(f\"{'='*60}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Tính toán lại số lượng review và sao trung bình thực tế\n",
    "        review_stats = (\n",
    "            review_df.groupBy(\"business_id\" , 'review_ts')\n",
    "            .agg(\n",
    "                count(\"review_id\").alias(\"actual_review_count\"),\n",
    "                avg(\"stars\").alias(\"actual_avg_stars\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Gộp với thông tin cửa hàng\n",
    "        result = (\n",
    "            business_df.join(review_stats, \"business_id\", \"inner\")\n",
    "            .select(\n",
    "                \"business_id\",\n",
    "                \"name\",\n",
    "                \"city\",\n",
    "                \"state\",\n",
    "                \"categories\",\n",
    "                \"stars\",\n",
    "                \"review_count\",\n",
    "                \"actual_review_count\",\n",
    "                \"actual_avg_stars\" ,\n",
    "                # 'review_ts' ,\n",
    "                'business_ts'\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    # ================================================================\n",
    "    # 8. Phân tích cảm xúc đánh giá theo thành phố\n",
    "    # ================================================================\n",
    "\n",
    "    def yelp_city_sentiment_summary(business_df, review_df, user_df):\n",
    "        b = business_df.alias(\"b\")\n",
    "        r = review_df.alias(\"r\")\n",
    "        u = user_df.alias(\"u\")\n",
    "\n",
    "        # =========================\n",
    "        # JOIN + SELECT CLEAN\n",
    "        # =========================\n",
    "        df = (\n",
    "            r.join(\n",
    "                b.select(\"business_id\", \"city\"),\n",
    "                on=\"business_id\",\n",
    "                how=\"inner\"\n",
    "            )\n",
    "            .join(\n",
    "                u.select(\n",
    "                    \"user_id\",\n",
    "                    F.col(\"name\").alias(\"user_name\"),\n",
    "                    F.col(\"fans\").alias(\"user_fans\"),\n",
    "                    F.col(\"useful\").alias(\"user_useful\")\n",
    "                ),\n",
    "                on=\"user_id\",\n",
    "                how=\"inner\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # =========================\n",
    "        # SENTIMENT FROM STARS\n",
    "        # =========================\n",
    "        df = df.withColumn(\n",
    "            \"sentiment\",\n",
    "            F.when(F.col(\"stars\") >= 4, \"Positive\")\n",
    "            .when(F.col(\"stars\") == 3, \"Neutral\")\n",
    "            .otherwise(\"Negative\")\n",
    "        )\n",
    "\n",
    "        # =========================\n",
    "        # PIVOT SENTIMENT BY CITY\n",
    "        # =========================\n",
    "        sentiment_pivot = (\n",
    "            df.groupBy(\"city\")\n",
    "            .pivot(\"sentiment\", [\"Positive\", \"Neutral\", \"Negative\"])\n",
    "            .agg(F.count(\"review_id\"))\n",
    "            .fillna(0)\n",
    "        )\n",
    "\n",
    "        # =========================\n",
    "        # 5. CITY METRICS\n",
    "        # =========================\n",
    "        city_metrics = (\n",
    "            df.groupBy(\"city\")\n",
    "            .agg(\n",
    "                F.count(\"review_id\").alias(\"total_reviews\"),\n",
    "                F.round(F.avg(\"stars\"), 2).alias(\"avg_stars\"),\n",
    "                F.countDistinct(\"business_id\").alias(\"unique_businesses\"),\n",
    "                F.countDistinct(\"user_id\").alias(\"unique_users\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # =========================\n",
    "        # USER INFLUENCE SCORE\n",
    "        # =========================\n",
    "        df = df.withColumn(\n",
    "            \"influence_score\",\n",
    "            F.col(\"user_useful\") + F.col(\"user_fans\") * 2\n",
    "        )\n",
    "\n",
    "        # =========================\n",
    "        # WINDOW FUNCTION\n",
    "        # =========================\n",
    "        w = Window.partitionBy(\"city\").orderBy(F.desc(\"influence_score\"))\n",
    "\n",
    "        top_user_per_city = (\n",
    "            df.withColumn(\"rank\", F.row_number().over(w))\n",
    "            .filter(F.col(\"rank\") == 1)\n",
    "            .select(\n",
    "                \"city\",\n",
    "                \"user_name\",\n",
    "                \"influence_score\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        \n",
    "        final_df = (\n",
    "            city_metrics\n",
    "            .join(sentiment_pivot, on=\"city\", how=\"left\")\n",
    "            .join(top_user_per_city, on=\"city\", how=\"left\")\n",
    "            .orderBy(F.desc(\"total_reviews\"))\n",
    "        )\n",
    "\n",
    "        return final_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08970af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Analysis 1: Top 10 Selling Products (Last 10 days)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Analysis 2: Top 10 Stores by Product Diversity\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Analysis 3: Top 10 Rated Products (Min 50 reviews)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Analysis 4: Top 10 Stores by Positive Reviews (>= 4 stars)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Analysis 2: Peak Review Hours (Activity Over Time)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Analysis 3: Top 20 Categories by Review Count\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Analysis 4: Store Statistics Summary\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "t1 = YelpAnalytics.top_selling_products_recent(review , business , 10 , 10) \n",
    "t2 = YelpAnalytics.top_stores_by_product_count(business , 10)\n",
    "t3 = YelpAnalytics.top_rated_products( business , review , 50 ,10)\n",
    "t4 = YelpAnalytics.top_stores_by_positive_reviews(business , review , 4 , 10)\n",
    "t5 = YelpAnalytics.get_peak_hours(review) \n",
    "t6 = YelpAnalytics.get_top_categories(business , review , 20)\n",
    "t7 = YelpAnalytics.get_store_stats(business , review)\n",
    "t8 = YelpAnalytics.yelp_city_sentiment_summary(business , review , user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43a13e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "t1.repartition(1).write.mode(\"append\").json(\"../ElasticSearch/top_selling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32c472d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "t2.repartition(1).write.mode(\"append\").json(\"../ElasticSearch/diverse_store\")\n",
    "t3.repartition(1).write.mode(\"append\").json(\"../ElasticSearch/best_rated\")\n",
    "t4.repartition(1).write.mode(\"append\").json(\"../ElasticSearch/most_positive\")\n",
    "t5.repartition(1).write.mode(\"append\").json(\"../ElasticSearch/peak_hours\")\n",
    "t6.repartition(1).write.mode(\"append\").json(\"../ElasticSearch/top_categories\")\n",
    "t7.repartition(1).write.mode(\"append\").json(\"../ElasticSearch/store_stats\")\n",
    "t8.repartition(1).write.mode(\"append\").json(\"../ElasticSearch/city_sentiment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
